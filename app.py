import streamlit as st
import yt_dlp
import os
import pandas as pd
from datetime import datetime
import requests
from bs4 import BeautifulSoup
from keyword_analyzer import KeywordAnalyzer, KeywordDataExporter
import plotly.express as px
import plotly.graph_objects as go

def get_channel_id(channel_url):
    """ì±„ë„ URLì—ì„œ ì±„ë„ IDë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        response = requests.get(channel_url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # ì±„ë„ IDê°€ í¬í•¨ëœ ë©”íƒ€ íƒœê·¸ ì°¾ê¸°
            meta_tags = soup.find_all('meta', {'property': 'og:url'})
            for tag in meta_tags:
                content = tag.get('content', '')
                if 'channel/' in content:
                    return content.split('channel/')[-1]
    except Exception as e:
        st.error(f"ì±„ë„ ID ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    return None

def get_channel_info(channel_url):
    """ì±„ë„ ì •ë³´ì™€ ë¹„ë””ì˜¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    ydl_opts = {
        'quiet': True,
        'extract_flat': True,
        'force_generic_extractor': True,
        'no_warnings': True,
        'ignoreerrors': True
    }
    
    try:
        # ë¨¼ì € ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
        channel_id = get_channel_id(channel_url)
        if channel_id:
            channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            result = ydl.extract_info(channel_url, download=False)
            if result and 'entries' in result:
                return result
            else:
                # ì±„ë„ URLë¡œ ì‹œë„
                result = ydl.extract_info(channel_url.replace("/videos", ""), download=False)
                return result
    except Exception as e:
        st.error(f"ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

def format_duration(duration):
    """ì´ˆ ë‹¨ìœ„ ì‹œê°„ì„ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not duration:
        return "00:00"
    minutes = int(duration) // 60
    seconds = int(duration) % 60
    return f"{minutes}:{seconds:02d}"

def format_date(date_str):
    """YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not date_str or len(date_str) != 8:
        return "Unknown"
    return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

st.set_page_config(page_title='YouTube Channel Manager', layout='wide')
st.title('ğŸ¬ YouTube Channel Manager - Video Downloader & Keyword Analysis')

# Create tabs
tab1, tab2, tab3 = st.tabs(['ğŸ“¥ Video Downloader', 'ğŸ” Keyword Analysis', 'ğŸ“Š Trend Analysis'])

# Initialize keyword analyzer
analyzer = KeywordAnalyzer()
exporter = KeywordDataExporter()

with tab1:

    # ì±„ë„ URL ë˜ëŠ” username ì…ë ¥
    channel_input = st.text_input('YouTube ì±„ë„ URL ë˜ëŠ” usernameì„ ì…ë ¥í•˜ì„¸ìš”:',
                                help='ì˜ˆ: https://www.youtube.com/@Seul_Ku ë˜ëŠ” @Seul_Ku')

    if channel_input:
        try:
            with st.spinner('ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                # URL í˜•ì‹ í™•ì¸ ë° ë³€í™˜
                if not channel_input.startswith('http'):
                    if not channel_input.startswith('@'):
                        channel_input = f"@{channel_input}"
                    channel_input = f"https://www.youtube.com/{channel_input}"

                # ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                channel_info = get_channel_info(channel_input)

                if not channel_info or 'entries' not in channel_info:
                    st.error('ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URL í˜•ì‹ì„ ì‹œë„í•´ë³´ì„¸ìš”.')
                    st.info('ì‹œë„í•´ë³¼ ìˆ˜ ìˆëŠ” URL í˜•ì‹:\n1. https://www.youtube.com/@username\n2. https://www.youtube.com/c/channelname\n3. https://www.youtube.com/channel/channel_id')
                    st.stop()

                # ì±„ë„ëª… í‘œì‹œ
                st.success(f'ì±„ë„ëª…: {channel_info.get("uploader", "Unknown")}')

                # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
                download_path = st.text_input('ë‹¤ìš´ë¡œë“œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”:', value='downloads')
                if not os.path.exists(download_path):
                    os.makedirs(download_path)

                # ë¹„ë””ì˜¤ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                videos = []
                for entry in channel_info['entries']:
                    if entry:
                        videos.append({
                            'title': entry.get('title', 'Unknown'),
                            'url': f"https://www.youtube.com/watch?v={entry['id']}",
                            'duration': format_duration(entry.get('duration', 0)),
                            'view_count': entry.get('view_count', 0),
                            'upload_date': format_date(entry.get('upload_date', 'Unknown'))
                        })

                if videos:
                    df = pd.DataFrame(videos)
                    st.dataframe(df)

                    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                    st.subheader('ë‹¤ìš´ë¡œë“œ ì˜µì…˜')
                    col1, col2 = st.columns(2)
                    with col1:
                        resolution = st.selectbox('í•´ìƒë„ ì„ íƒ:',
                                               ['1080p', '720p', '480p', '360p'])
                    with col2:
                        format_option = st.selectbox('í¬ë§· ì„ íƒ:',
                                                   ['mp4', 'mkv'])

                    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ìƒíƒœ í‘œì‹œì¤„
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    if st.button('ì„ íƒí•œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ'):
                        total_videos = len(videos)
                        for i, video in enumerate(videos):
                            try:
                                ydl_opts = {
                                    'format': f'bestvideo[height<={resolution[:-1]}]+bestaudio/best[height<={resolution[:-1]}]',
                                    'outtmpl': os.path.join(download_path, '%(title)s.%(ext)s'),
                                    'merge_output_format': format_option,
                                    'quiet': True,
                                }

                                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                                    status_text.text(f'ë‹¤ìš´ë¡œë“œ ì¤‘: {video["title"]}')
                                    ydl.download([video['url']])
                                    progress = (i + 1) / total_videos
                                    progress_bar.progress(progress)
                                    st.success(f'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video["title"]}')

                            except Exception as e:
                                st.error(f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {video["title"]} - {str(e)}')

                        status_text.text('ëª¨ë“  ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!')
                else:
                    st.warning('ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

        except Exception as e:
            st.error(f'ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
            st.info('ì˜¬ë°”ë¥¸ ì±„ë„ URLì´ë‚˜ usernameì„ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.')

# Tab 2: Keyword Analysis
with tab2:
    st.header('ğŸ” í¬í„¸ í‚¤ì›Œë“œ ë¶„ì„')
    st.markdown('**Google, Naver, Daumì˜ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ë¶„ì„ (Black Kiwië³´ë‹¤ í–¥ìƒëœ ë¶„ì„)**')

    analysis_mode = st.radio('ë¶„ì„ ëª¨ë“œ ì„ íƒ:',
                            ['ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„', 'ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ', 'ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ'],
                            horizontal=True)

    if analysis_mode == 'ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„':
        st.subheader('ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„')
        keyword = st.text_input('ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:', placeholder='ì˜ˆ: íŒŒì´ì¬ íŠœí† ë¦¬ì–¼')

        if keyword:
            with st.spinner('ğŸ”„ ë‹¤ì¤‘ í¬í„¸ ë¶„ì„ ì¤‘...'):
                analysis_result = analyzer.analyze_multi_portal(keyword)

            # ê²°ê³¼ í‘œì‹œ
            col1, col2, col3, col4 = st.columns(4)

            portals = ['Google', 'Naver', 'Daum', 'YouTube']
            for idx, portal in enumerate(portals):
                portal_data = analysis_result['portals'].get(portal, {})
                with [col1, col2, col3, col4][idx]:
                    st.metric(
                        portal,
                        f"{portal_data.get('estimated_search_volume', 0):,}",
                        delta=portal_data.get('trend', 'N/A')
                    )

            st.divider()

            # ìƒì„¸ ë¶„ì„
            for portal in portals:
                with st.expander(f'ğŸ“Š {portal} ìƒì„¸ ë¶„ì„'):
                    portal_data = analysis_result['portals'].get(portal, {})
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**ê²€ìƒ‰ëŸ‰:** {portal_data.get('estimated_search_volume', 'N/A'):,}")
                        st.write(f"**íŠ¸ë Œë“œ:** {portal_data.get('trend', 'N/A')}")
                        if portal == 'Google':
                            st.write(f"**ê²½ìŸë„:** {portal_data.get('competition_level', 'N/A')}")

                    with col2:
                        if 'related_keywords' in portal_data:
                            st.write("**ê´€ë ¨ í‚¤ì›Œë“œ:**")
                            for kw in portal_data.get('related_keywords', []):
                                st.write(f"  â€¢ {kw}")

            # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
            st.divider()
            st.subheader('ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°')
            col1, col2 = st.columns(2)

            with col1:
                if st.button('JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°'):
                    result_msg = exporter.export_to_json(analysis_result, f'keyword_analysis_{keyword}.json')
                    st.info(result_msg)

            with col2:
                if st.button('CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
                    df = pd.DataFrame([
                        {
                            'Keyword': keyword,
                            'Portal': portal,
                            'Search Volume': analysis_result['portals'].get(portal, {}).get('estimated_search_volume', 0),
                            'Trend': analysis_result['portals'].get(portal, {}).get('trend', 'N/A')
                        }
                        for portal in portals
                    ])
                    result_msg = exporter.export_to_csv(df, f'keyword_analysis_{keyword}.csv')
                    st.info(result_msg)

    elif analysis_mode == 'ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ':
        st.subheader('ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„')
        keywords_input = st.text_area('ë¹„êµí•  í‚¤ì›Œë“œë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©):',
                                     placeholder='í‚¤ì›Œë“œ1\ní‚¤ì›Œë“œ2\ní‚¤ì›Œë“œ3')

        if keywords_input:
            keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]

            if st.button('ë¹„êµ ë¶„ì„ ì‹œì‘'):
                with st.spinner('ğŸ”„ ë¹„êµ ë¶„ì„ ì¤‘...'):
                    comparison_df = analyzer.compare_keywords(keywords)

                st.dataframe(comparison_df, use_container_width=True)

                # ì‹œê°í™”
                st.subheader('ğŸ“ˆ ë¹„êµ ì°¨íŠ¸')

                # í¬í„¸ë³„ ê²€ìƒ‰ëŸ‰ ë¹„êµ
                fig = px.bar(
                    comparison_df,
                    x='Keyword',
                    y=['Google Volume', 'Naver Volume', 'Daum Volume', 'YouTube Volume'],
                    title='í¬í„¸ë³„ ê²€ìƒ‰ëŸ‰ ë¹„êµ',
                    barmode='group'
                )
                st.plotly_chart(fig, use_container_width=True)

                # í‰ê·  ê²€ìƒ‰ëŸ‰ ë¹„êµ
                fig2 = px.bar(
                    comparison_df,
                    x='Keyword',
                    y='Average',
                    title='í‰ê·  ê²€ìƒ‰ëŸ‰ ë¹„êµ',
                    color='Average'
                )
                st.plotly_chart(fig2, use_container_width=True)

                # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                st.divider()
                if st.button('ë¹„êµ ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
                    result_msg = exporter.export_to_csv(comparison_df, 'keyword_comparison.csv')
                    st.info(result_msg)

    else:  # ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ
        st.subheader('ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ')
        channel_name = st.text_input('ì±„ë„ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:', placeholder='ì˜ˆ: íŒŒì´ì¬ íŠœí† ë¦¬ì–¼ ì±„ë„')
        video_titles_input = st.text_area('ë¹„ë””ì˜¤ ì œëª©ë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©):',
                                         placeholder='íŒŒì´ì¬ ê¸°ì´ˆ\níŒŒì´ì¬ ì¤‘ê¸‰\níŒŒì´ì¬ ê³ ê¸‰')

        if channel_name and video_titles_input:
            video_titles = [title.strip() for title in video_titles_input.split('\n') if title.strip()]

            if st.button('ì¶”ì²œ í‚¤ì›Œë“œ ìƒì„±'):
                with st.spinner('ğŸ”„ ì¶”ì²œ í‚¤ì›Œë“œ ìƒì„± ì¤‘...'):
                    recommended_keywords = analyzer.get_keyword_recommendations(channel_name, video_titles)

                st.success('âœ… ì¶”ì²œ í‚¤ì›Œë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!')

                # ì¶”ì²œ í‚¤ì›Œë“œ í‘œì‹œ
                st.subheader('ì¶”ì²œ í‚¤ì›Œë“œ')
                cols = st.columns(3)
                for idx, keyword in enumerate(recommended_keywords):
                    with cols[idx % 3]:
                        st.write(f"ğŸ¯ `{keyword}`")

# Tab 3: Trend Analysis
with tab3:
    st.header('ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ (Advanced)')
    st.markdown('**Black Kiwië³´ë‹¤ í–¥ìƒëœ 30ì¼ íŠ¸ë Œë“œ ë¶„ì„**')

    keyword = st.text_input('íŠ¸ë Œë“œë¥¼ ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:',
                           placeholder='ì˜ˆ: ì¸ê³µì§€ëŠ¥')
    days = st.slider('ë¶„ì„ ê¸°ê°„ (ì¼ìˆ˜):', min_value=7, max_value=90, value=30, step=7)

    if keyword:
        with st.spinner(f'ğŸ”„ {days}ì¼ê°„ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...'):
            trend_analysis = analyzer.get_trend_analysis(keyword, days)

        # ìš”ì•½ ì •ë³´
        st.subheader('ğŸ“ˆ íŠ¸ë Œë“œ ìš”ì•½')
        summary = trend_analysis['summary']

        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric('í‰ê·  ê²€ìƒ‰ëŸ‰', f"{summary['average_volume']:.0f}")
        with col2:
            st.metric('í”¼í¬ ê²€ìƒ‰ëŸ‰', f"{summary['peak_volume']:.0f}")
        with col3:
            st.metric('ìµœì†Œ ê²€ìƒ‰ëŸ‰', f"{summary['min_volume']:.0f}")
        with col4:
            st.metric('í‰ê·  ê´€ì‹¬ë„', f"{summary['average_interest']:.0f}")
        with col5:
            st.metric('ë³€ë™ì„±', f"{summary['volatility']:.0f}")

        # íŠ¸ë Œë“œ ë¼ì¸ ì°¨íŠ¸
        st.subheader('ğŸ“‰ ê²€ìƒ‰ëŸ‰ ì¶”ì´')
        trend_df = pd.DataFrame(trend_analysis['data'])

        fig = px.line(
            trend_df,
            x='date',
            y='search_volume',
            title=f'"{keyword}" í‚¤ì›Œë“œ {days}ì¼ ê²€ìƒ‰ëŸ‰ ì¶”ì´',
            markers=True,
            labels={'date': 'ë‚ ì§œ', 'search_volume': 'ê²€ìƒ‰ëŸ‰'}
        )
        fig.update_layout(hovermode='x unified')
        st.plotly_chart(fig, use_container_width=True)

        # ê´€ì‹¬ë„ ì¶”ì´
        st.subheader('ğŸ’¡ ê´€ì‹¬ë„ ì¶”ì´')
        fig2 = px.area(
            trend_df,
            x='date',
            y='interest_level',
            title=f'"{keyword}" í‚¤ì›Œë“œ {days}ì¼ ê´€ì‹¬ë„ ì¶”ì´',
            labels={'date': 'ë‚ ì§œ', 'interest_level': 'ê´€ì‹¬ë„'}
        )
        st.plotly_chart(fig2, use_container_width=True)

        # íŠ¸ë Œë“œ ì˜ˆì¸¡
        st.divider()
        st.subheader('ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡')
        prediction = trend_analysis['prediction']

        col1, col2, col3 = st.columns(3)
        with col1:
            trend_emoji = 'ğŸ“ˆ' if prediction['predicted_trend'] == 'increasing' else ('ğŸ“‰' if prediction['predicted_trend'] == 'decreasing' else 'â¡ï¸')
            st.metric('ì˜ˆì¸¡ íŠ¸ë Œë“œ', f"{trend_emoji} {prediction['predicted_trend']}")
        with col2:
            st.metric('ì„±ì¥ë¥ ', f"{prediction['growth_rate']:.2f}%")
        with col3:
            st.metric('ì‹ ë¢°ë„', prediction['confidence'])

        # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
        st.subheader('ğŸ“‹ ìƒì„¸ ë°ì´í„°')
        st.dataframe(trend_df, use_container_width=True)

        # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        st.divider()
        if st.button('íŠ¸ë Œë“œ ë¶„ì„ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°'):
            result_msg = exporter.export_to_json(trend_analysis, f'trend_analysis_{keyword}.json')
            st.info(result_msg)

        if st.button('íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
            result_msg = exporter.export_to_csv(trend_df, f'trend_analysis_{keyword}.csv')
            st.info(result_msg)
