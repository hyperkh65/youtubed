import streamlit as st
import yt_dlp
import os
import pandas as pd
from datetime import datetime
import requests
from bs4 import BeautifulSoup
from keyword_analyzer import KeywordAnalyzer, KeywordDataExporter
import plotly.express as px
import plotly.graph_objects as go

def get_channel_id(channel_url):
    """ì±„ë„ URLì—ì„œ ì±„ë„ IDë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        response = requests.get(channel_url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # ì±„ë„ IDê°€ í¬í•¨ëœ ë©”íƒ€ íƒœê·¸ ì°¾ê¸°
            meta_tags = soup.find_all('meta', {'property': 'og:url'})
            for tag in meta_tags:
                content = tag.get('content', '')
                if 'channel/' in content:
                    return content.split('channel/')[-1]
    except Exception as e:
        st.error(f"ì±„ë„ ID ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    return None

def get_channel_info(channel_url):
    """ì±„ë„ ì •ë³´ì™€ ë¹„ë””ì˜¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    ydl_opts = {
        'quiet': True,
        'extract_flat': True,
        'force_generic_extractor': True,
        'no_warnings': True,
        'ignoreerrors': True
    }
    
    try:
        # ë¨¼ì € ì±„ë„ ID ê°€ì ¸ì˜¤ê¸°
        channel_id = get_channel_id(channel_url)
        if channel_id:
            channel_url = f"https://www.youtube.com/channel/{channel_id}/videos"
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            result = ydl.extract_info(channel_url, download=False)
            if result and 'entries' in result:
                return result
            else:
                # ì±„ë„ URLë¡œ ì‹œë„
                result = ydl.extract_info(channel_url.replace("/videos", ""), download=False)
                return result
    except Exception as e:
        st.error(f"ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

def format_duration(duration):
    """ì´ˆ ë‹¨ìœ„ ì‹œê°„ì„ MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not duration:
        return "00:00"
    minutes = int(duration) // 60
    seconds = int(duration) % 60
    return f"{minutes}:{seconds:02d}"

def format_date(date_str):
    """YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not date_str or len(date_str) != 8:
        return "Unknown"
    return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"

st.set_page_config(page_title='YouTube Channel Manager', layout='wide')
st.title('ğŸ¬ YouTube Channel Manager - Video Downloader & Keyword Analysis')

# Create tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    'ğŸ“¥ Video Downloader',
    'ğŸ” Keyword Analysis',
    'ğŸ“Š Trend Analysis',
    'ğŸ¯ Advanced Features',
    'ğŸ“ˆ Performance & History',
    'âš™ï¸ Settings'
])

# Initialize keyword analyzer
analyzer = KeywordAnalyzer()
exporter = KeywordDataExporter()

with tab1:

    # ì±„ë„ URL ë˜ëŠ” username ì…ë ¥
    channel_input = st.text_input('YouTube ì±„ë„ URL ë˜ëŠ” usernameì„ ì…ë ¥í•˜ì„¸ìš”:',
                                help='ì˜ˆ: https://www.youtube.com/@Seul_Ku ë˜ëŠ” @Seul_Ku')

    if channel_input:
        try:
            with st.spinner('ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                # URL í˜•ì‹ í™•ì¸ ë° ë³€í™˜
                if not channel_input.startswith('http'):
                    if not channel_input.startswith('@'):
                        channel_input = f"@{channel_input}"
                    channel_input = f"https://www.youtube.com/{channel_input}"

                # ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                channel_info = get_channel_info(channel_input)

                if not channel_info or 'entries' not in channel_info:
                    st.error('ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URL í˜•ì‹ì„ ì‹œë„í•´ë³´ì„¸ìš”.')
                    st.info('ì‹œë„í•´ë³¼ ìˆ˜ ìˆëŠ” URL í˜•ì‹:\n1. https://www.youtube.com/@username\n2. https://www.youtube.com/c/channelname\n3. https://www.youtube.com/channel/channel_id')
                    st.stop()

                # ì±„ë„ëª… í‘œì‹œ
                st.success(f'ì±„ë„ëª…: {channel_info.get("uploader", "Unknown")}')

                # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ì„¤ì •
                download_path = st.text_input('ë‹¤ìš´ë¡œë“œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”:', value='downloads')
                if not os.path.exists(download_path):
                    os.makedirs(download_path)

                # ë¹„ë””ì˜¤ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                videos = []
                for entry in channel_info['entries']:
                    if entry:
                        videos.append({
                            'title': entry.get('title', 'Unknown'),
                            'url': f"https://www.youtube.com/watch?v={entry['id']}",
                            'duration': format_duration(entry.get('duration', 0)),
                            'view_count': entry.get('view_count', 0),
                            'upload_date': format_date(entry.get('upload_date', 'Unknown'))
                        })

                if videos:
                    df = pd.DataFrame(videos)
                    st.dataframe(df)

                    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
                    st.subheader('ë‹¤ìš´ë¡œë“œ ì˜µì…˜')
                    col1, col2 = st.columns(2)
                    with col1:
                        resolution = st.selectbox('í•´ìƒë„ ì„ íƒ:',
                                               ['1080p', '720p', '480p', '360p'])
                    with col2:
                        format_option = st.selectbox('í¬ë§· ì„ íƒ:',
                                                   ['mp4', 'mkv'])

                    # ì§„í–‰ ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ìƒíƒœ í‘œì‹œì¤„
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    if st.button('ì„ íƒí•œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ'):
                        total_videos = len(videos)
                        for i, video in enumerate(videos):
                            try:
                                ydl_opts = {
                                    'format': f'bestvideo[height<={resolution[:-1]}]+bestaudio/best[height<={resolution[:-1]}]',
                                    'outtmpl': os.path.join(download_path, '%(title)s.%(ext)s'),
                                    'merge_output_format': format_option,
                                    'quiet': True,
                                }

                                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                                    status_text.text(f'ë‹¤ìš´ë¡œë“œ ì¤‘: {video["title"]}')
                                    ydl.download([video['url']])
                                    progress = (i + 1) / total_videos
                                    progress_bar.progress(progress)
                                    st.success(f'ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video["title"]}')

                            except Exception as e:
                                st.error(f'ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {video["title"]} - {str(e)}')

                        status_text.text('ëª¨ë“  ë‹¤ìš´ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!')
                else:
                    st.warning('ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')

        except Exception as e:
            st.error(f'ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}')
            st.info('ì˜¬ë°”ë¥¸ ì±„ë„ URLì´ë‚˜ usernameì„ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.')

# Tab 2: Keyword Analysis
with tab2:
    st.header('ğŸ” í¬í„¸ í‚¤ì›Œë“œ ë¶„ì„')
    st.markdown('**Google, Naver, Daumì˜ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ë¶„ì„ (Black Kiwië³´ë‹¤ í–¥ìƒëœ ë¶„ì„)**')

    analysis_mode = st.radio('ë¶„ì„ ëª¨ë“œ ì„ íƒ:',
                            ['ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„', 'ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ', 'ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ'],
                            horizontal=True)

    if analysis_mode == 'ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„':
        st.subheader('ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ì„')
        keyword = st.text_input('ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:', placeholder='ì˜ˆ: íŒŒì´ì¬ íŠœí† ë¦¬ì–¼')

        if keyword:
            with st.spinner('ğŸ”„ ë‹¤ì¤‘ í¬í„¸ ë¶„ì„ ì¤‘...'):
                analysis_result = analyzer.analyze_multi_portal(keyword)

            # ê²°ê³¼ í‘œì‹œ
            col1, col2, col3, col4 = st.columns(4)

            portals = ['Google', 'Naver', 'Daum', 'YouTube']
            for idx, portal in enumerate(portals):
                portal_data = analysis_result['portals'].get(portal, {})
                with [col1, col2, col3, col4][idx]:
                    st.metric(
                        portal,
                        f"{portal_data.get('estimated_search_volume', 0):,}",
                        delta=portal_data.get('trend', 'N/A')
                    )

            st.divider()

            # ìƒì„¸ ë¶„ì„
            for portal in portals:
                with st.expander(f'ğŸ“Š {portal} ìƒì„¸ ë¶„ì„'):
                    portal_data = analysis_result['portals'].get(portal, {})
                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**ê²€ìƒ‰ëŸ‰:** {portal_data.get('estimated_search_volume', 'N/A'):,}")
                        st.write(f"**íŠ¸ë Œë“œ:** {portal_data.get('trend', 'N/A')}")
                        if portal == 'Google':
                            st.write(f"**ê²½ìŸë„:** {portal_data.get('competition_level', 'N/A')}")

                    with col2:
                        if 'related_keywords' in portal_data:
                            st.write("**ê´€ë ¨ í‚¤ì›Œë“œ:**")
                            for kw in portal_data.get('related_keywords', []):
                                st.write(f"  â€¢ {kw}")

            # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
            st.divider()
            st.subheader('ğŸ“¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°')
            col1, col2 = st.columns(2)

            with col1:
                if st.button('JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°'):
                    result_msg = exporter.export_to_json(analysis_result, f'keyword_analysis_{keyword}.json')
                    st.info(result_msg)

            with col2:
                if st.button('CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
                    df = pd.DataFrame([
                        {
                            'Keyword': keyword,
                            'Portal': portal,
                            'Search Volume': analysis_result['portals'].get(portal, {}).get('estimated_search_volume', 0),
                            'Trend': analysis_result['portals'].get(portal, {}).get('trend', 'N/A')
                        }
                        for portal in portals
                    ])
                    result_msg = exporter.export_to_csv(df, f'keyword_analysis_{keyword}.csv')
                    st.info(result_msg)

    elif analysis_mode == 'ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ':
        st.subheader('ì—¬ëŸ¬ í‚¤ì›Œë“œ ë¹„êµ ë¶„ì„')
        keywords_input = st.text_area('ë¹„êµí•  í‚¤ì›Œë“œë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©):',
                                     placeholder='í‚¤ì›Œë“œ1\ní‚¤ì›Œë“œ2\ní‚¤ì›Œë“œ3')

        if keywords_input:
            keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]

            if st.button('ë¹„êµ ë¶„ì„ ì‹œì‘'):
                with st.spinner('ğŸ”„ ë¹„êµ ë¶„ì„ ì¤‘...'):
                    comparison_df = analyzer.compare_keywords(keywords)

                st.dataframe(comparison_df, use_container_width=True)

                # ì‹œê°í™”
                st.subheader('ğŸ“ˆ ë¹„êµ ì°¨íŠ¸')

                # í¬í„¸ë³„ ê²€ìƒ‰ëŸ‰ ë¹„êµ
                fig = px.bar(
                    comparison_df,
                    x='Keyword',
                    y=['Google Volume', 'Naver Volume', 'Daum Volume', 'YouTube Volume'],
                    title='í¬í„¸ë³„ ê²€ìƒ‰ëŸ‰ ë¹„êµ',
                    barmode='group'
                )
                st.plotly_chart(fig, use_container_width=True)

                # í‰ê·  ê²€ìƒ‰ëŸ‰ ë¹„êµ
                fig2 = px.bar(
                    comparison_df,
                    x='Keyword',
                    y='Average',
                    title='í‰ê·  ê²€ìƒ‰ëŸ‰ ë¹„êµ',
                    color='Average'
                )
                st.plotly_chart(fig2, use_container_width=True)

                # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
                st.divider()
                if st.button('ë¹„êµ ê²°ê³¼ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
                    result_msg = exporter.export_to_csv(comparison_df, 'keyword_comparison.csv')
                    st.info(result_msg)

    else:  # ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ
        st.subheader('ì±„ë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì²œ')
        channel_name = st.text_input('ì±„ë„ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:', placeholder='ì˜ˆ: íŒŒì´ì¬ íŠœí† ë¦¬ì–¼ ì±„ë„')
        video_titles_input = st.text_area('ë¹„ë””ì˜¤ ì œëª©ë“¤ì„ ì…ë ¥í•˜ì„¸ìš” (í•œ ì¤„ì— í•˜ë‚˜ì”©):',
                                         placeholder='íŒŒì´ì¬ ê¸°ì´ˆ\níŒŒì´ì¬ ì¤‘ê¸‰\níŒŒì´ì¬ ê³ ê¸‰')

        if channel_name and video_titles_input:
            video_titles = [title.strip() for title in video_titles_input.split('\n') if title.strip()]

            if st.button('ì¶”ì²œ í‚¤ì›Œë“œ ìƒì„±'):
                with st.spinner('ğŸ”„ ì¶”ì²œ í‚¤ì›Œë“œ ìƒì„± ì¤‘...'):
                    recommended_keywords = analyzer.get_keyword_recommendations(channel_name, video_titles)

                st.success('âœ… ì¶”ì²œ í‚¤ì›Œë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!')

                # ì¶”ì²œ í‚¤ì›Œë“œ í‘œì‹œ
                st.subheader('ì¶”ì²œ í‚¤ì›Œë“œ')
                cols = st.columns(3)
                for idx, keyword in enumerate(recommended_keywords):
                    with cols[idx % 3]:
                        st.write(f"ğŸ¯ `{keyword}`")

# Tab 3: Trend Analysis
with tab3:
    st.header('ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ (Advanced)')
    st.markdown('**Black Kiwië³´ë‹¤ í–¥ìƒëœ 30ì¼ íŠ¸ë Œë“œ ë¶„ì„**')

    keyword = st.text_input('íŠ¸ë Œë“œë¥¼ ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:',
                           placeholder='ì˜ˆ: ì¸ê³µì§€ëŠ¥')
    days = st.slider('ë¶„ì„ ê¸°ê°„ (ì¼ìˆ˜):', min_value=7, max_value=90, value=30, step=7)

    if keyword:
        with st.spinner(f'ğŸ”„ {days}ì¼ê°„ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...'):
            trend_analysis = analyzer.get_trend_analysis(keyword, days)

        # ìš”ì•½ ì •ë³´
        st.subheader('ğŸ“ˆ íŠ¸ë Œë“œ ìš”ì•½')
        summary = trend_analysis['summary']

        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric('í‰ê·  ê²€ìƒ‰ëŸ‰', f"{summary['average_volume']:.0f}")
        with col2:
            st.metric('í”¼í¬ ê²€ìƒ‰ëŸ‰', f"{summary['peak_volume']:.0f}")
        with col3:
            st.metric('ìµœì†Œ ê²€ìƒ‰ëŸ‰', f"{summary['min_volume']:.0f}")
        with col4:
            st.metric('í‰ê·  ê´€ì‹¬ë„', f"{summary['average_interest']:.0f}")
        with col5:
            st.metric('ë³€ë™ì„±', f"{summary['volatility']:.0f}")

        # íŠ¸ë Œë“œ ë¼ì¸ ì°¨íŠ¸
        st.subheader('ğŸ“‰ ê²€ìƒ‰ëŸ‰ ì¶”ì´')
        trend_df = pd.DataFrame(trend_analysis['data'])

        fig = px.line(
            trend_df,
            x='date',
            y='search_volume',
            title=f'"{keyword}" í‚¤ì›Œë“œ {days}ì¼ ê²€ìƒ‰ëŸ‰ ì¶”ì´',
            markers=True,
            labels={'date': 'ë‚ ì§œ', 'search_volume': 'ê²€ìƒ‰ëŸ‰'}
        )
        fig.update_layout(hovermode='x unified')
        st.plotly_chart(fig, use_container_width=True)

        # ê´€ì‹¬ë„ ì¶”ì´
        st.subheader('ğŸ’¡ ê´€ì‹¬ë„ ì¶”ì´')
        fig2 = px.area(
            trend_df,
            x='date',
            y='interest_level',
            title=f'"{keyword}" í‚¤ì›Œë“œ {days}ì¼ ê´€ì‹¬ë„ ì¶”ì´',
            labels={'date': 'ë‚ ì§œ', 'interest_level': 'ê´€ì‹¬ë„'}
        )
        st.plotly_chart(fig2, use_container_width=True)

        # íŠ¸ë Œë“œ ì˜ˆì¸¡
        st.divider()
        st.subheader('ğŸ”® íŠ¸ë Œë“œ ì˜ˆì¸¡')
        prediction = trend_analysis['prediction']

        col1, col2, col3 = st.columns(3)
        with col1:
            trend_emoji = 'ğŸ“ˆ' if prediction['predicted_trend'] == 'increasing' else ('ğŸ“‰' if prediction['predicted_trend'] == 'decreasing' else 'â¡ï¸')
            st.metric('ì˜ˆì¸¡ íŠ¸ë Œë“œ', f"{trend_emoji} {prediction['predicted_trend']}")
        with col2:
            st.metric('ì„±ì¥ë¥ ', f"{prediction['growth_rate']:.2f}%")
        with col3:
            st.metric('ì‹ ë¢°ë„', prediction['confidence'])

        # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
        st.subheader('ğŸ“‹ ìƒì„¸ ë°ì´í„°')
        st.dataframe(trend_df, use_container_width=True)

        # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        st.divider()
        if st.button('íŠ¸ë Œë“œ ë¶„ì„ì„ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°'):
            result_msg = exporter.export_to_json(trend_analysis, f'trend_analysis_{keyword}.json')
            st.info(result_msg)

        if st.button('íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°'):
            result_msg = exporter.export_to_csv(trend_df, f'trend_analysis_{keyword}.csv')
            st.info(result_msg)

# Tab 4: Advanced Features
with tab4:
    st.header('ğŸ¯ ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥')

    advanced_mode = st.radio('ë¶„ì„ ìœ í˜• ì„ íƒ:',
                            ['ìˆ/ë¡±í…Œì¼ í‚¤ì›Œë“œ', 'ì‹¤ì‹œê°„ ì¶”ì²œ', 'ê²½ìŸì‚¬ ë¶„ì„', 'ê²€ìƒ‰ ì˜ë„ ë¶„ì„'],
                            horizontal=True)

    if advanced_mode == 'ìˆ/ë¡±í…Œì¼ í‚¤ì›Œë“œ':
        st.subheader('ğŸ“Š ìˆ/ë¡±í…Œì¼ í‚¤ì›Œë“œ ë¶„ì„')
        st.markdown('**ìˆ í‚¤ì›Œë“œ(1-2ë‹¨ì–´)ì™€ ë¡±í…Œì¼ í‚¤ì›Œë“œ(3ë‹¨ì–´+) ìƒì„¸ ë¶„ì„**')

        keyword = st.text_input('ë¶„ì„í•  í‚¤ì›Œë“œ:', placeholder='ì˜ˆ: íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° íŠœí† ë¦¬ì–¼')

        if keyword:
            with st.spinner('ğŸ”„ ìˆ/ë¡±í…Œì¼ ë¶„ì„ ì¤‘...'):
                analysis = analyzer.analyze_short_long_keywords(keyword)

            col1, col2 = st.columns(2)

            with col1:
                st.write('### ğŸ“Œ ìˆí…Œì¼ í‚¤ì›Œë“œ (ë†’ì€ ê²€ìƒ‰ëŸ‰)')
                if analysis['short_keywords']:
                    for kw in analysis['short_keywords']:
                        st.write(f"""
                        **{kw['keyword']}**
                        - ê²€ìƒ‰ëŸ‰: {kw['volume']:,}
                        - ë‚œì´ë„: {kw['difficulty']}/100
                        """)

            with col2:
                st.write('### ğŸ¯ ë¡±í…Œì¼ í‚¤ì›Œë“œ (ë‚®ì€ ê²½ìŸë„)')
                if analysis['long_keywords']:
                    for kw in analysis['long_keywords']:
                        st.write(f"""
                        **{kw['keyword']}**
                        - ê²€ìƒ‰ëŸ‰: {kw['volume']:,}
                        - ë‚œì´ë„: {kw['difficulty']}/100
                        - ì „í™˜ ê°€ëŠ¥ì„±: {kw['conversion_potential']:.1%}
                        """)

            # ë¹„êµ ë¶„ì„ ì‹œê°í™”
            st.divider()
            st.subheader('ğŸ“ˆ ìˆ/ë¡±í…Œì¼ ë¹„êµ ë¶„ì„')

            comparison = analysis['comparison']

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric('ìˆí…Œì¼ í‰ê·  ê²€ìƒ‰ëŸ‰', f"{comparison['short_tail_avg_volume']:.0f}")
            with col2:
                st.metric('ë¡±í…Œì¼ í‰ê·  ê²€ìƒ‰ëŸ‰', f"{comparison['long_tail_avg_volume']:.0f}")
            with col3:
                st.metric('ìˆí…Œì¼ ë‚œì´ë„', f"{comparison['short_tail_avg_difficulty']:.0f}")
            with col4:
                st.metric('ë¡±í…Œì¼ ë‚œì´ë„', f"{comparison['long_tail_avg_difficulty']:.0f}")

            st.info(f"ğŸ’¡ **ì¶”ì²œ:** {comparison['recommendation']}")

    elif advanced_mode == 'ì‹¤ì‹œê°„ ì¶”ì²œ':
        st.subheader('ğŸ’¡ ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ì¶”ì²œ')
        st.markdown('**ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì„ í†µí•œ ìµœì ì˜ í‚¤ì›Œë“œ ì¶”ì²œ**')

        col1, col2 = st.columns(2)
        with col1:
            keywords_input = st.text_area('ê¸°ë³¸ í‚¤ì›Œë“œë“¤ (í•œ ì¤„ì— í•˜ë‚˜):',
                                         placeholder='íŒŒì´ì¬\në¨¸ì‹ ëŸ¬ë‹\në°ì´í„°ê³¼í•™',
                                         height=100)
        with col2:
            channel_topic = st.text_input('ì±„ë„ ì£¼ì œ (ì„ íƒì‚¬í•­):', placeholder='ì˜ˆ: ê¸°ìˆ /í”„ë¡œê·¸ë˜ë°')

        if keywords_input and st.button('ì‹¤ì‹œê°„ ì¶”ì²œ ìƒì„±'):
            keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]

            with st.spinner('ğŸ”„ ìµœì ì˜ í‚¤ì›Œë“œ ì¶”ì²œ ì¤‘...'):
                recommendations = analyzer.get_realtime_recommendations(keywords, channel_topic)

            st.success('âœ… ì¶”ì²œ í‚¤ì›Œë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!')

            # ì¶”ì²œ ê²°ê³¼ í‘œì‹œ
            rec_df = pd.DataFrame([
                {
                    'Keyword': r['keyword'],
                    'Score': f"{r['score']:.1f}",
                    'Type': r.get('type', 'N/A'),
                    'Volume': f"{r.get('volume', 0):,}",
                    'Difficulty': r.get('difficulty', 0),
                    'Trend': r.get('trend', 'N/A')
                }
                for r in recommendations
            ])

            st.dataframe(rec_df, use_container_width=True)

            # ì ìˆ˜ë³„ ì‹œê°í™”
            fig = px.bar(
                pd.DataFrame(recommendations).sort_values('score'),
                x='keyword',
                y='score',
                title='í‚¤ì›Œë“œ ì¶”ì²œ ì ìˆ˜',
                color='score'
            )
            st.plotly_chart(fig, use_container_width=True)

    elif advanced_mode == 'ê²½ìŸì‚¬ ë¶„ì„':
        st.subheader('âš”ï¸ ê²½ìŸì‚¬ í‚¤ì›Œë“œ ë¶„ì„')
        st.markdown('**ê²½ìŸì‚¬ì˜ í‚¤ì›Œë“œ ì „ëµì„ ë¶„ì„í•˜ê³  ê¸°íšŒ ë°œêµ´**')

        col1, col2 = st.columns(2)

        with col1:
            competitor_input = st.text_area('ê²½ìŸì‚¬ í‚¤ì›Œë“œë“¤:',
                                           placeholder='ê²½ìŸì‚¬1\nê²½ìŸì‚¬2\nê²½ìŸì‚¬3',
                                           height=120)

        with col2:
            your_input = st.text_area('ìš°ë¦¬ì˜ í‚¤ì›Œë“œë“¤:',
                                     placeholder='ìš°ë¦¬1\nìš°ë¦¬2\nìš°ë¦¬3',
                                     height=120)

        if competitor_input and your_input and st.button('ê²½ìŸì‚¬ ë¶„ì„ ì‹œì‘'):
            competitor_kws = [kw.strip() for kw in competitor_input.split('\n') if kw.strip()]
            your_kws = [kw.strip() for kw in your_input.split('\n') if kw.strip()]

            with st.spinner('ğŸ”„ ê²½ìŸ ë¶„ì„ ì¤‘...'):
                comp_analysis = analyzer.analyze_competitor_keywords(competitor_kws, your_kws)

            # ê²°ê³¼ í‘œì‹œ
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric('ê³µí†µ í‚¤ì›Œë“œ', len(comp_analysis['overlap_keywords']))
            with col2:
                st.metric('ê²½ìŸì‚¬ ë…ì ', len(comp_analysis['competitor_unique']))
            with col3:
                st.metric('ìš°ë¦¬ ë…ì ', len(comp_analysis['your_unique']))

            st.divider()

            # ë°œê²¬ëœ ê¸°íšŒ
            st.subheader('ğŸ¯ ë°œê²¬ëœ ê¸°íšŒ í‚¤ì›Œë“œ')

            if comp_analysis['opportunities']:
                opp_df = pd.DataFrame([
                    {
                        'Keyword': opp['keyword'],
                        'Opportunity Score': f"{opp['opportunity_score']:.1f}",
                        'Search Volume': f"{opp['volume']:,}",
                        'Difficulty': f"{opp['difficulty']}/100"
                    }
                    for opp in comp_analysis['opportunities'][:10]
                ])

                st.dataframe(opp_df, use_container_width=True)

                # ê¸°íšŒ ì‹œê°í™”
                fig = px.scatter(
                    pd.DataFrame(comp_analysis['opportunities'][:10]),
                    x='difficulty',
                    y='volume',
                    size='opportunity_score',
                    hover_data=['keyword'],
                    title='ê¸°íšŒ í‚¤ì›Œë“œ ë§¤íŠ¸ë¦­ìŠ¤ (X: ë‚œì´ë„, Y: ê²€ìƒ‰ëŸ‰)',
                    labels={'difficulty': 'ë‚œì´ë„', 'volume': 'ê²€ìƒ‰ëŸ‰'}
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning('ë°œê²¬ëœ ê¸°íšŒê°€ ì—†ìŠµë‹ˆë‹¤.')

    else:  # ê²€ìƒ‰ ì˜ë„ ë¶„ì„
        st.subheader('ğŸ” ê²€ìƒ‰ ì˜ë„ ë¶„ì„')
        st.markdown('**Informational, Navigational, Commercial, Transactional**')

        keyword = st.text_input('í‚¤ì›Œë“œ ì…ë ¥:', placeholder='ì˜ˆ: ìµœê³ ì˜ ë…¸íŠ¸ë¶ ê°€ê²© ë¹„êµ')

        if keyword:
            with st.spinner('ğŸ”„ ê²€ìƒ‰ ì˜ë„ ë¶„ì„ ì¤‘...'):
                intent_analysis = analyzer.analyze_search_intent(keyword)

            intent_emoji = {
                'informational': 'ğŸ“š',
                'navigational': 'ğŸ§­',
                'commercial': 'ğŸ›ï¸',
                'transactional': 'ğŸ’³'
            }

            intent_names = {
                'informational': 'ì •ë³´ ê²€ìƒ‰ (ì •ë³´ ì–»ê¸°)',
                'navigational': 'ë„¤ë¹„ê²Œì´ì…˜ (ì‚¬ì´íŠ¸ ì°¾ê¸°)',
                'commercial': 'ìƒì—… (ë¹„êµ/ë¦¬ë·°)',
                'transactional': 'ê±°ë˜ (êµ¬ë§¤)'
            }

            col1, col2 = st.columns(2)

            with col1:
                st.write('### ğŸ¯ ì£¼ìš” ê²€ìƒ‰ ì˜ë„')
                primary = intent_analysis['primary_intent']
                st.success(f"{intent_emoji.get(primary, '')} {intent_names.get(primary, 'Unknown')}")
                st.write(f"ì‹ ë¢°ë„: {intent_analysis['confidence']:.1%}")

            with col2:
                st.write('### ğŸ“Š ì˜ë„ë³„ ì ìˆ˜')
                scores = intent_analysis['intent_scores']

                fig = px.bar(
                    x=list(scores.keys()),
                    y=list(scores.values()),
                    title='ê²€ìƒ‰ ì˜ë„ ë¶„í¬',
                    labels={'x': 'ì˜ë„ ìœ í˜•', 'y': 'ì ìˆ˜'}
                )
                st.plotly_chart(fig, use_container_width=True)

# Tab 5: Performance & History
with tab5:
    st.header('ğŸ“ˆ ì„±ëŠ¥ ì˜ˆì¸¡ & íˆìŠ¤í† ë¦¬')

    perf_mode = st.radio('ë¶„ì„ ì„ íƒ:',
                        ['ì„±ëŠ¥ ì˜ˆì¸¡', 'ê³„ì ˆì„± ê°ì§€', 'í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬'],
                        horizontal=True)

    if perf_mode == 'ì„±ëŠ¥ ì˜ˆì¸¡':
        st.subheader('ğŸ”® í–¥í›„ 3ê°œì›” í‚¤ì›Œë“œ ì„±ëŠ¥ ì˜ˆì¸¡')

        keyword = st.text_input('ì˜ˆì¸¡í•  í‚¤ì›Œë“œ:', placeholder='ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ')

        if keyword:
            with st.spinner('ğŸ”„ ì„±ëŠ¥ ì˜ˆì¸¡ ì¤‘...'):
                prediction = analyzer.predict_keyword_performance(keyword, months=3)

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric('í˜„ì¬ ê²€ìƒ‰ëŸ‰', f"{prediction['current_volume']:.0f}")
            with col2:
                trend_emoji = 'ğŸ“ˆ' if prediction['predicted_trend'] == 'increasing' else 'ğŸ“‰'
                st.metric('ì˜ˆì¸¡ íŠ¸ë Œë“œ', f"{trend_emoji} {prediction['predicted_trend']}")
            with col3:
                st.metric('ì˜ˆì¸¡ ì‹ ë¢°ë„', f"{prediction['confidence']:.1f}%")

            # ì˜ˆì¸¡ ê·¸ë˜í”„
            st.subheader('ğŸ“Š 3ê°œì›” ê²€ìƒ‰ëŸ‰ ì˜ˆì¸¡')

            pred_df = pd.DataFrame({
                'Date': prediction['prediction_dates'],
                'Predicted Volume': prediction['predicted_volumes']
            })

            fig = px.line(
                pred_df,
                x='Date',
                y='Predicted Volume',
                title=f'"{keyword}" ì˜ˆìƒ ê²€ìƒ‰ëŸ‰ ë³€í™”',
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)

    elif perf_mode == 'ê³„ì ˆì„± ê°ì§€':
        st.subheader('ğŸ“… ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„')

        keyword = st.text_input('ê³„ì ˆì„±ì„ ë¶„ì„í•  í‚¤ì›Œë“œ:', placeholder='ì˜ˆ: í¬ë¦¬ìŠ¤ë§ˆìŠ¤')

        if keyword:
            with st.spinner('ğŸ”„ ê³„ì ˆì„± ë¶„ì„ ì¤‘...'):
                seasonality = analyzer.detect_seasonality(keyword, days=365)

            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric('ê³„ì ˆì„± ê°•ë„', f"{seasonality['seasonality_strength']:.2f}")
            with col2:
                st.write('**í”¼í¬ ì›”:**')
                for month in seasonality['peak_months']:
                    st.write(f"  â€¢ {month}")
            with col3:
                st.write('**ì €ì  ì›”:**')
                for month in seasonality['low_months']:
                    st.write(f"  â€¢ {month}")

            # ì›”ë³„ íŒ¨í„´
            st.subheader('ğŸ“ˆ ì›”ë³„ ê²€ìƒ‰ëŸ‰ íŒ¨í„´')

            monthly_df = pd.DataFrame({
                'Month': list(seasonality['monthly_pattern'].keys()),
                'Search Volume': list(seasonality['monthly_pattern'].values())
            })

            fig = px.bar(
                monthly_df,
                x='Month',
                y='Search Volume',
                title='ì›”ë³„ í‰ê·  ê²€ìƒ‰ëŸ‰',
                color='Search Volume'
            )
            st.plotly_chart(fig, use_container_width=True)

            # í¬ìŠ¤íŒ… ì¼ì • ì¶”ì²œ
            st.divider()
            st.subheader('ğŸ“… ìµœì  í¬ìŠ¤íŒ… ì¼ì •')

            recommendation = seasonality['recommendation']

            col1, col2 = st.columns(2)
            with col1:
                st.info(f"**ìµœê³ ì˜ ë‹¬:** {recommendation['best_month']}")
                st.info(f"**ìµœê³ ì˜ ìš”ì¼:** {recommendation['best_day']}")
            with col2:
                st.warning(f"**í”¼í•´ì•¼ í•  ë‹¬:** {', '.join(recommendation['avoid_months'])}")
                st.info(f"**ì¶”ì²œ ì£¼ê¸°:** {recommendation['posting_frequency']}")

    else:  # í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬
        st.subheader('ğŸ“œ í‚¤ì›Œë“œ ë¶„ì„ íˆìŠ¤í† ë¦¬')

        col1, col2 = st.columns(2)

        with col1:
            keyword = st.text_input('ê²€ìƒ‰ í‚¤ì›Œë“œ:', placeholder='ì˜ˆ: íŒŒì´ì¬')
            days = st.slider('ì¡°íšŒ ê¸°ê°„ (ì¼):', 1, 90, 30)

        with col2:
            st.write('**ìœ ëª… í‚¤ì›Œë“œ Top 10**')
            try:
                top_keywords = analyzer.db.get_top_keywords(10)
                if not top_keywords.empty:
                    for idx, row in top_keywords.iterrows():
                        st.write(f"{idx+1}. {row['keyword']} ({int(row['count'])}íšŒ)")
                else:
                    st.info('íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.')
            except:
                st.info('íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')

        if keyword:
            try:
                history = analyzer.db.get_analysis_history(keyword, days)

                if not history.empty:
                    st.dataframe(history, use_container_width=True)

                    # ì‹œê°„ëŒ€ë³„ ì¶”ì´
                    history_df = history.copy()
                    history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
                    history_df = history_df.sort_values('timestamp')

                    fig = px.line(
                        history_df,
                        x='timestamp',
                        y='search_volume',
                        color='portal',
                        title=f'"{keyword}" íˆìŠ¤í† ë¦¬'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info('ë¶„ì„ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.')
            except Exception as e:
                st.warning(f'íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}')

# Tab 6: Settings
with tab6:
    st.header('âš™ï¸ ì„¤ì • & ë„êµ¬')

    settings_mode = st.radio('ì„¤ì • ì„ íƒ:',
                            ['ë°ì´í„° ë‚´ë³´ë‚´ê¸°', 'ë¶„ì„ ë¦¬í¬íŠ¸', 'ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´'],
                            horizontal=True)

    if settings_mode == 'ë°ì´í„° ë‚´ë³´ë‚´ê¸°':
        st.subheader('ğŸ“¥ í‚¤ì›Œë“œ ë¶„ì„ ë°ì´í„° ë‚´ë³´ë‚´ê¸°')

        keyword = st.text_input('ë‚´ë³´ë‚¼ í‚¤ì›Œë“œ:', placeholder='ì˜ˆ: íŒŒì´ì¬ íŠœí† ë¦¬ì–¼')

        if keyword:
            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button('JSON í˜•ì‹'):
                    analysis = analyzer.analyze_multi_portal(keyword)
                    msg = exporter.export_to_json(analysis, f'{keyword}_analysis.json')
                    st.success(msg)

            with col2:
                if st.button('CSV í˜•ì‹'):
                    df = pd.DataFrame([
                        {
                            'Keyword': keyword,
                            'Analysis Date': datetime.now().isoformat()
                        }
                    ])
                    msg = exporter.export_to_csv(df, f'{keyword}_analysis.csv')
                    st.success(msg)

            with col3:
                if st.button('ë³´ê³ ì„œ ìƒì„±'):
                    analysis = analyzer.analyze_multi_portal(keyword)
                    msg = exporter.generate_report(analysis, f'{keyword}_report.json')
                    st.success(msg)

    elif settings_mode == 'ë¶„ì„ ë¦¬í¬íŠ¸':
        st.subheader('ğŸ“Š ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±')

        keywords_input = st.text_area('ë¶„ì„í•  í‚¤ì›Œë“œë“¤ (í•œ ì¤„ì— í•˜ë‚˜):',
                                     placeholder='í‚¤ì›Œë“œ1\ní‚¤ì›Œë“œ2\ní‚¤ì›Œë“œ3',
                                     height=100)

        if st.button('ë¦¬í¬íŠ¸ ìƒì„±'):
            if keywords_input:
                keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]

                with st.spinner('ğŸ”„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...'):
                    all_analysis = {}

                    for kw in keywords:
                        all_analysis[kw] = {
                            'multi_portal': analyzer.analyze_multi_portal(kw),
                            'short_long': analyzer.analyze_short_long_keywords(kw),
                            'intent': analyzer.analyze_search_intent(kw)
                        }

                    msg = exporter.generate_report(all_analysis, 'comprehensive_report.json')
                    st.success(msg)
                    st.info(f'âœ… {len(keywords)}ê°œ í‚¤ì›Œë“œì— ëŒ€í•œ ì¢…í•© ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')
            else:
                st.warning('í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')

    else:  # ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´
        st.subheader('ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´')

        col1, col2 = st.columns(2)

        with col1:
            st.write('**ë°ì´í„°ë² ì´ìŠ¤ ìœ„ì¹˜:**')
            st.code(analyzer.db.db_path, language='text')

            if st.button('ğŸ—‘ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”'):
                try:
                    if os.path.exists(analyzer.db.db_path):
                        os.remove(analyzer.db.db_path)
                        st.success('âœ… ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
                    else:
                        st.info('ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.')
                except Exception as e:
                    st.error(f'ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}')

        with col2:
            st.write('**ì‹œìŠ¤í…œ ì •ë³´:**')
            st.write(f"- ë¶„ì„ ëª¨ë“ˆ: Advanced Keyword Analyzer v2.0")
            st.write(f"- ì§€ì› í¬í„¸: Google, Naver, Daum, YouTube")
            st.write(f"- ë°ì´í„° ì €ì¥ì†Œ: SQLite")
            st.write(f"- ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
